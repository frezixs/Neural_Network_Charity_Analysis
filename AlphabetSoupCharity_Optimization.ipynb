{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a623aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"charity_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04bfeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(['EIN', 'NAME'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07b74ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE    17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column \n",
    "application_df.nunique().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26a108db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x194b27ed6c8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts of APPLICATION_TYPE\n",
    "application_df[\"APPLICATION_TYPE\"].value_counts().plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44c7465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "app_num =application_df[\"APPLICATION_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1abef3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "Other     7262\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace Bins into dataframe- APPLICATION\n",
    "replace_app= app_num[app_num < 5000].index.tolist()\n",
    "\n",
    "for i in replace_app:\n",
    "    application_df.APPLICATION_TYPE= application_df.APPLICATION_TYPE.replace(i,\"Other\")\n",
    "    \n",
    "application_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc374748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check CLASSIFICATION \n",
    "class_col= application_df[\"CLASSIFICATION\"].value_counts()\n",
    "class_col.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b9975c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace Bins into dataframe- CLASSIFICATION\n",
    "replace_class= class_col[class_col < 5000].index.tolist()\n",
    "\n",
    "for j in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(j, \"Other\")\n",
    "    \n",
    "application_df.CLASSIFICATION.value_counts().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c17e09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable lists \n",
    "application_categorical = application_df.dtypes[application_df.dtypes==\"object\"].index.tolist()\n",
    "application_df[application_categorical].nunique().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ac4b071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T3  AFFILIATION_CompanySponsored  \\\n",
       "0                     1.0                  0.0                           0.0   \n",
       "1                     0.0                  1.0                           0.0   \n",
       "2                     1.0                  0.0                           1.0   \n",
       "3                     0.0                  1.0                           1.0   \n",
       "4                     0.0                  1.0                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  CLASSIFICATION_C1000  \\\n",
       "0                0.0                   0.0                   1.0   \n",
       "1                0.0                   0.0                   0.0   \n",
       "2                0.0                   0.0                   0.0   \n",
       "3                0.0                   0.0                   0.0   \n",
       "4                0.0                   0.0                   1.0   \n",
       "\n",
       "   CLASSIFICATION_C2000  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                   0.0  ...                0.0                     0.0   \n",
       "1                   1.0  ...                1.0                     0.0   \n",
       "2                   0.0  ...                0.0                     0.0   \n",
       "3                   1.0  ...                0.0                     1.0   \n",
       "4                   0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance \n",
    "enc= OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder unsing categorical list \n",
    "encode_df= pd.DataFrame(enc.fit_transform(application_df[application_categorical]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe \n",
    "encode_df.columns= enc.get_feature_names(application_categorical)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49df52b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     1.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     1.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  AFFILIATION_CompanySponsored  \\\n",
       "0                  0.0                           0.0   \n",
       "1                  1.0                           0.0   \n",
       "2                  0.0                           1.0   \n",
       "3                  1.0                           1.0   \n",
       "4                  1.0                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                0.0  ...                0.0                     0.0   \n",
       "1                0.0  ...                1.0                     0.0   \n",
       "2                0.0  ...                0.0                     0.0   \n",
       "3                0.0  ...                0.0                     1.0   \n",
       "4                0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge One-Hot encoded features and drop the originals\n",
    "prep_application_df= application_df.merge(encode_df,left_index=True, right_index=True).drop(columns= application_categorical)\n",
    "prep_application_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953a664",
   "metadata": {},
   "source": [
    "# Drop Noisy Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f073193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     1.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     1.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  AFFILIATION_CompanySponsored  \\\n",
       "0                  0.0                           0.0   \n",
       "1                  1.0                           0.0   \n",
       "2                  0.0                           1.0   \n",
       "3                  1.0                           1.0   \n",
       "4                  1.0                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Regional  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                   0.0  ...                0.0                     0.0   \n",
       "1                   0.0  ...                1.0                     0.0   \n",
       "2                   0.0  ...                0.0                     0.0   \n",
       "3                   0.0  ...                0.0                     1.0   \n",
       "4                   0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Noisy Features \n",
    "drop_noisy_application_df= prep_application_df.drop(columns= [\"USE_CASE_Other\",\"AFFILIATION_Other\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72500c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data \n",
    "y=drop_noisy_application_df[\"IS_SUCCESSFUL\"].values\n",
    "X=drop_noisy_application_df.drop(columns=[\"IS_SUCCESSFUL\"]).values\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=.2, random_state= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2196d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StandArdScaler \n",
    "scaler= StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler= scaler.fit(X_train)\n",
    "\n",
    "# Scale the data \n",
    "X_train_scaled= X_scaler.transform(X_train)\n",
    "X_test_scaled= X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f141eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               3200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 13,401\n",
      "Trainable params: 13,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "num_input = len(X_train[0])\n",
    "hidden_nodes1 = 100\n",
    "hidden_nodes2 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes1, input_dim = num_input,\n",
    "                                    activation =\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes1, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units = 1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d3dc7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "858/858 [==============================] - 2s 1ms/step - loss: 0.5978 - accuracy: 0.7011\n",
      "Epoch 2/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5882 - accuracy: 0.7079\n",
      "Epoch 3/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5857 - accuracy: 0.7074\n",
      "Epoch 4/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5839 - accuracy: 0.7082\n",
      "Epoch 5/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.7089\n",
      "Epoch 6/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5828 - accuracy: 0.7107\n",
      "Epoch 7/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5817 - accuracy: 0.7103\n",
      "Epoch 8/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5811 - accuracy: 0.7103\n",
      "Epoch 9/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5808 - accuracy: 0.7113\n",
      "Epoch 10/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5807 - accuracy: 0.7120\n",
      "Epoch 11/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5800 - accuracy: 0.7119\n",
      "Epoch 12/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5797 - accuracy: 0.7125\n",
      "Epoch 13/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5794 - accuracy: 0.7131\n",
      "Epoch 14/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5789 - accuracy: 0.7120\n",
      "Epoch 15/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5786 - accuracy: 0.7123\n",
      "Epoch 16/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5786 - accuracy: 0.7133\n",
      "Epoch 17/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5783 - accuracy: 0.7143\n",
      "Epoch 18/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.7133\n",
      "Epoch 19/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5780 - accuracy: 0.7143\n",
      "Epoch 20/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5778 - accuracy: 0.7141\n",
      "Epoch 21/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5778 - accuracy: 0.7137\n",
      "Epoch 22/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.7143\n",
      "Epoch 23/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5777 - accuracy: 0.7141\n",
      "Epoch 24/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5778 - accuracy: 0.7134\n",
      "Epoch 25/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5770 - accuracy: 0.7147\n",
      "Epoch 26/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5774 - accuracy: 0.7150\n",
      "Epoch 27/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5771 - accuracy: 0.7137\n",
      "Epoch 28/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5767 - accuracy: 0.7142\n",
      "Epoch 29/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5764 - accuracy: 0.7139\n",
      "Epoch 30/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5769 - accuracy: 0.7147\n",
      "Epoch 31/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5765 - accuracy: 0.7153\n",
      "Epoch 32/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5765 - accuracy: 0.7143\n",
      "Epoch 33/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5763 - accuracy: 0.7145\n",
      "Epoch 34/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5762 - accuracy: 0.7146\n",
      "Epoch 35/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5764 - accuracy: 0.7147\n",
      "Epoch 36/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5757 - accuracy: 0.7151\n",
      "Epoch 37/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5762 - accuracy: 0.7150\n",
      "Epoch 38/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5761 - accuracy: 0.7151\n",
      "Epoch 39/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5757 - accuracy: 0.7153\n",
      "Epoch 40/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5756 - accuracy: 0.7153\n",
      "Epoch 41/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5758 - accuracy: 0.7156\n",
      "Epoch 42/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5753 - accuracy: 0.7157\n",
      "Epoch 43/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5756 - accuracy: 0.7154\n",
      "Epoch 44/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5757 - accuracy: 0.7149\n",
      "Epoch 45/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5754 - accuracy: 0.7156\n",
      "Epoch 46/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5754 - accuracy: 0.7157\n",
      "Epoch 47/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5752 - accuracy: 0.7158\n",
      "Epoch 48/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5752 - accuracy: 0.7155\n",
      "Epoch 49/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5752 - accuracy: 0.7159\n",
      "Epoch 50/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5749 - accuracy: 0.7161\n",
      "Epoch 51/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5748 - accuracy: 0.7162\n",
      "Epoch 52/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5747 - accuracy: 0.7160\n",
      "Epoch 53/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7156\n",
      "Epoch 54/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5748 - accuracy: 0.7163\n",
      "Epoch 55/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5745 - accuracy: 0.7164\n",
      "Epoch 56/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5744 - accuracy: 0.7166\n",
      "Epoch 57/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5744 - accuracy: 0.7160\n",
      "Epoch 58/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5742 - accuracy: 0.7154\n",
      "Epoch 59/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5742 - accuracy: 0.7165\n",
      "Epoch 60/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5742 - accuracy: 0.7163\n",
      "Epoch 61/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5738 - accuracy: 0.7161\n",
      "Epoch 62/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5743 - accuracy: 0.7158\n",
      "Epoch 63/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7158\n",
      "Epoch 64/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5741 - accuracy: 0.7162\n",
      "Epoch 65/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.7165\n",
      "Epoch 66/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5738 - accuracy: 0.7161\n",
      "Epoch 67/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.7170\n",
      "Epoch 68/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5738 - accuracy: 0.7162\n",
      "Epoch 69/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.7162\n",
      "Epoch 70/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5737 - accuracy: 0.7163\n",
      "Epoch 71/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5734 - accuracy: 0.7158\n",
      "Epoch 72/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5738 - accuracy: 0.7163\n",
      "Epoch 73/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.7165\n",
      "Epoch 74/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5731 - accuracy: 0.7163\n",
      "Epoch 75/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5738 - accuracy: 0.7162\n",
      "Epoch 76/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5732 - accuracy: 0.7168\n",
      "Epoch 77/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5732 - accuracy: 0.7163\n",
      "Epoch 78/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5733 - accuracy: 0.7167\n",
      "Epoch 79/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7167\n",
      "Epoch 80/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5734 - accuracy: 0.7168\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5732 - accuracy: 0.7165\n",
      "Epoch 82/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5732 - accuracy: 0.7167\n",
      "Epoch 83/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5728 - accuracy: 0.7166\n",
      "Epoch 84/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7166\n",
      "Epoch 85/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.7167\n",
      "Epoch 86/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5733 - accuracy: 0.7166\n",
      "Epoch 87/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5729 - accuracy: 0.7161\n",
      "Epoch 88/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5728 - accuracy: 0.7174\n",
      "Epoch 89/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5728 - accuracy: 0.7174\n",
      "Epoch 90/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5727 - accuracy: 0.7171\n",
      "Epoch 91/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5732 - accuracy: 0.7168\n",
      "Epoch 92/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7165\n",
      "Epoch 93/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5726 - accuracy: 0.7169\n",
      "Epoch 94/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5728 - accuracy: 0.7161\n",
      "Epoch 95/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5723 - accuracy: 0.7169\n",
      "Epoch 96/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5738 - accuracy: 0.7167\n",
      "Epoch 97/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5723 - accuracy: 0.7168\n",
      "Epoch 98/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5723 - accuracy: 0.7168\n",
      "Epoch 99/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7168\n",
      "Epoch 100/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5731 - accuracy: 0.7169\n",
      "Epoch 101/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5726 - accuracy: 0.7169\n",
      "Epoch 102/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7173\n",
      "Epoch 103/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7170\n",
      "Epoch 104/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7172\n",
      "Epoch 105/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7168\n",
      "Epoch 106/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5726 - accuracy: 0.7164\n",
      "Epoch 107/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7171\n",
      "Epoch 108/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5726 - accuracy: 0.7165\n",
      "Epoch 109/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5724 - accuracy: 0.7170\n",
      "Epoch 110/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5724 - accuracy: 0.7169\n",
      "Epoch 111/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5726 - accuracy: 0.7170\n",
      "Epoch 112/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5723 - accuracy: 0.7168\n",
      "Epoch 113/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.7169\n",
      "Epoch 114/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5723 - accuracy: 0.7174\n",
      "Epoch 115/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.7169\n",
      "Epoch 116/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7167\n",
      "Epoch 117/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5722 - accuracy: 0.7172\n",
      "Epoch 118/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7169\n",
      "Epoch 119/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5720 - accuracy: 0.7167\n",
      "Epoch 120/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.7168\n",
      "Epoch 121/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.7170\n",
      "Epoch 122/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5725 - accuracy: 0.7169\n",
      "Epoch 123/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7171\n",
      "Epoch 124/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7166\n",
      "Epoch 125/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7169\n",
      "Epoch 126/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.7169\n",
      "Epoch 127/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7172\n",
      "Epoch 128/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.7173\n",
      "Epoch 129/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.7168\n",
      "Epoch 130/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7171\n",
      "Epoch 131/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7169\n",
      "Epoch 132/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5719 - accuracy: 0.7172\n",
      "Epoch 133/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.7171\n",
      "Epoch 134/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7173\n",
      "Epoch 135/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5725 - accuracy: 0.7175\n",
      "Epoch 136/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7171\n",
      "Epoch 137/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7173\n",
      "Epoch 138/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7173\n",
      "Epoch 139/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7171\n",
      "Epoch 140/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7171\n",
      "Epoch 141/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7174\n",
      "Epoch 142/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5724 - accuracy: 0.7171\n",
      "Epoch 143/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5735 - accuracy: 0.7169\n",
      "Epoch 144/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7172\n",
      "Epoch 145/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7169\n",
      "Epoch 146/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7171\n",
      "Epoch 147/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.7174\n",
      "Epoch 148/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.7171\n",
      "Epoch 149/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7174\n",
      "Epoch 150/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5719 - accuracy: 0.7174\n",
      "Epoch 151/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5715 - accuracy: 0.7178\n",
      "Epoch 152/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5720 - accuracy: 0.7174\n",
      "Epoch 153/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7173\n",
      "Epoch 154/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7167\n",
      "Epoch 155/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5711 - accuracy: 0.7178\n",
      "Epoch 156/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7171\n",
      "Epoch 157/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5713 - accuracy: 0.7177\n",
      "Epoch 158/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7177\n",
      "Epoch 159/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7175\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7172\n",
      "Epoch 161/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7172\n",
      "Epoch 162/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5726 - accuracy: 0.7171\n",
      "Epoch 163/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.7170\n",
      "Epoch 164/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7175\n",
      "Epoch 165/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5713 - accuracy: 0.7172\n",
      "Epoch 166/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5712 - accuracy: 0.7180\n",
      "Epoch 167/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7175\n",
      "Epoch 168/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7174\n",
      "Epoch 169/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5711 - accuracy: 0.7178\n",
      "Epoch 170/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7172\n",
      "Epoch 171/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5715 - accuracy: 0.7173\n",
      "Epoch 172/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7169\n",
      "Epoch 173/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7178\n",
      "Epoch 174/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7176\n",
      "Epoch 175/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.7178\n",
      "Epoch 176/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7175\n",
      "Epoch 177/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7174\n",
      "Epoch 178/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7177\n",
      "Epoch 179/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7173\n",
      "Epoch 180/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5716 - accuracy: 0.7173\n",
      "Epoch 181/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5709 - accuracy: 0.7179\n",
      "Epoch 182/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7171\n",
      "Epoch 183/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7179\n",
      "Epoch 184/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5710 - accuracy: 0.7169\n",
      "Epoch 185/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7171\n",
      "Epoch 186/200\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5751 - accuracy: 0.7175\n",
      "Epoch 187/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.7171\n",
      "Epoch 188/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7176\n",
      "Epoch 189/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5711 - accuracy: 0.7177\n",
      "Epoch 190/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5708 - accuracy: 0.7181\n",
      "Epoch 191/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5707 - accuracy: 0.7173\n",
      "Epoch 192/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5710 - accuracy: 0.7174\n",
      "Epoch 193/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7173\n",
      "Epoch 194/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7175\n",
      "Epoch 195/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5709 - accuracy: 0.7171\n",
      "Epoch 196/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5706 - accuracy: 0.7175\n",
      "Epoch 197/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5723 - accuracy: 0.7175\n",
      "Epoch 198/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5709 - accuracy: 0.7178\n",
      "Epoch 199/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.7172\n",
      "Epoch 200/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5709 - accuracy: 0.7174\n",
      "215/215 - 0s - loss: 0.6148 - accuracy: 0.7136\n",
      "Loss:0.6148163676261902, Accuracy: 0.7135568261146545\n"
     ]
    }
   ],
   "source": [
    "# Compile the model \n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics= [\"accuracy\"])\n",
    "\n",
    "# Create callback that saves every 5 epochs\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Create a Callback that saves the weights every 5 epochs\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\n",
    "cp_callback= ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True, save_freq=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model= nn.fit(X_train_scaled, y_train, epochs=200, verbose=1, callbacks=[cp_callback])\n",
    "\n",
    "#Evaluate results\n",
    "model_loss, model_accuracy= nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss:{model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a71d1c",
   "metadata": {},
   "source": [
    "# 3 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d37d4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 100)               3200      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 15,851\n",
      "Trainable params: 15,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "num_input = len(X_train[0])\n",
    "hidden_nodes1 = 100\n",
    "hidden_nodes2 = 50\n",
    "hidden_node3= 25\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes1, input_dim = num_input,\n",
    "                                    activation =\"relu\"))\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units = hidden_nodes1, activation=\"relu\"))\n",
    "\n",
    "# Third Hidden Layer\n",
    "nn2.add(tf.keras.layers.Dense(units= hidden_node3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units = 1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0dd79e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5966 - accuracy: 0.7011\n",
      "Epoch 2/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5870 - accuracy: 0.7076\n",
      "Epoch 3/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5850 - accuracy: 0.7098\n",
      "Epoch 4/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5835 - accuracy: 0.7094\n",
      "Epoch 5/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5826 - accuracy: 0.7103\n",
      "Epoch 6/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5817 - accuracy: 0.7108\n",
      "Epoch 7/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5819 - accuracy: 0.7106\n",
      "Epoch 8/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5811 - accuracy: 0.7116\n",
      "Epoch 9/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5810 - accuracy: 0.7119\n",
      "Epoch 10/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5802 - accuracy: 0.7123\n",
      "Epoch 11/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5800 - accuracy: 0.7127\n",
      "Epoch 12/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5804 - accuracy: 0.7127\n",
      "Epoch 13/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5793 - accuracy: 0.7134\n",
      "Epoch 14/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5791 - accuracy: 0.7135\n",
      "Epoch 15/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5793 - accuracy: 0.7131\n",
      "Epoch 16/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5790 - accuracy: 0.7138\n",
      "Epoch 17/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5782 - accuracy: 0.7133\n",
      "Epoch 18/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5783 - accuracy: 0.7135\n",
      "Epoch 19/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5781 - accuracy: 0.7141\n",
      "Epoch 20/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5781 - accuracy: 0.7141\n",
      "Epoch 21/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5780 - accuracy: 0.7139\n",
      "Epoch 22/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5772 - accuracy: 0.7150\n",
      "Epoch 23/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5774 - accuracy: 0.7145\n",
      "Epoch 24/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5773 - accuracy: 0.7142\n",
      "Epoch 25/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5772 - accuracy: 0.7145\n",
      "Epoch 26/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5773 - accuracy: 0.7146\n",
      "Epoch 27/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5764 - accuracy: 0.7146\n",
      "Epoch 28/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5765 - accuracy: 0.7142\n",
      "Epoch 29/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5765 - accuracy: 0.7152\n",
      "Epoch 30/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5767 - accuracy: 0.7147\n",
      "Epoch 31/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5762 - accuracy: 0.7148\n",
      "Epoch 32/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5756 - accuracy: 0.7145\n",
      "Epoch 33/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5760 - accuracy: 0.7143\n",
      "Epoch 34/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5758 - accuracy: 0.7150\n",
      "Epoch 35/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5755 - accuracy: 0.7151\n",
      "Epoch 36/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5756 - accuracy: 0.7156\n",
      "Epoch 37/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5756 - accuracy: 0.7147\n",
      "Epoch 38/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5756 - accuracy: 0.7151\n",
      "Epoch 39/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5753 - accuracy: 0.7155\n",
      "Epoch 40/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5752 - accuracy: 0.7157\n",
      "Epoch 41/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5753 - accuracy: 0.7149\n",
      "Epoch 42/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5748 - accuracy: 0.7164\n",
      "Epoch 43/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5754 - accuracy: 0.7156\n",
      "Epoch 44/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5747 - accuracy: 0.7149\n",
      "Epoch 45/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5741 - accuracy: 0.7156\n",
      "Epoch 46/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5749 - accuracy: 0.7162\n",
      "Epoch 47/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5745 - accuracy: 0.7160\n",
      "Epoch 48/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5744 - accuracy: 0.7158\n",
      "Epoch 49/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5743 - accuracy: 0.7163\n",
      "Epoch 50/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5745 - accuracy: 0.7161\n",
      "Epoch 51/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5746 - accuracy: 0.7160\n",
      "Epoch 52/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5741 - accuracy: 0.7166\n",
      "Epoch 53/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5742 - accuracy: 0.7157\n",
      "Epoch 54/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5741 - accuracy: 0.7162\n",
      "Epoch 55/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5741 - accuracy: 0.7162\n",
      "Epoch 56/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5744 - accuracy: 0.7153\n",
      "Epoch 57/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5738 - accuracy: 0.7166\n",
      "Epoch 58/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5739 - accuracy: 0.7164\n",
      "Epoch 59/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5737 - accuracy: 0.7169\n",
      "Epoch 60/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5737 - accuracy: 0.7159\n",
      "Epoch 61/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5734 - accuracy: 0.7164\n",
      "Epoch 62/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5740 - accuracy: 0.7156\n",
      "Epoch 63/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5735 - accuracy: 0.7161\n",
      "Epoch 64/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5735 - accuracy: 0.7163\n",
      "Epoch 65/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5732 - accuracy: 0.7167\n",
      "Epoch 66/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5733 - accuracy: 0.7168\n",
      "Epoch 67/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5735 - accuracy: 0.7166\n",
      "Epoch 68/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5733 - accuracy: 0.7165\n",
      "Epoch 69/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5735 - accuracy: 0.7168\n",
      "Epoch 70/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5738 - accuracy: 0.7161\n",
      "Epoch 71/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5732 - accuracy: 0.7169\n",
      "Epoch 72/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5733 - accuracy: 0.7168\n",
      "Epoch 73/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.7165\n",
      "Epoch 74/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5731 - accuracy: 0.7168\n",
      "Epoch 75/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5724 - accuracy: 0.7172\n",
      "Epoch 76/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5729 - accuracy: 0.7166\n",
      "Epoch 77/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5725 - accuracy: 0.7167\n",
      "Epoch 78/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5733 - accuracy: 0.7168\n",
      "Epoch 79/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.7170\n",
      "Epoch 80/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5723 - accuracy: 0.7165\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5730 - accuracy: 0.7169\n",
      "Epoch 82/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5726 - accuracy: 0.7169\n",
      "Epoch 83/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5724 - accuracy: 0.7168\n",
      "Epoch 84/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5721 - accuracy: 0.7167\n",
      "Epoch 85/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5724 - accuracy: 0.7168\n",
      "Epoch 86/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.7164\n",
      "Epoch 87/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5722 - accuracy: 0.7167\n",
      "Epoch 88/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5726 - accuracy: 0.7171\n",
      "Epoch 89/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.7168\n",
      "Epoch 90/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.7168\n",
      "Epoch 91/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7168\n",
      "Epoch 92/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.7169\n",
      "Epoch 93/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7168\n",
      "Epoch 94/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.7173\n",
      "Epoch 95/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7170\n",
      "Epoch 96/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5724 - accuracy: 0.7173\n",
      "Epoch 97/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7170\n",
      "Epoch 98/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.7169\n",
      "Epoch 99/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.7172\n",
      "Epoch 100/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5719 - accuracy: 0.7173\n",
      "Epoch 101/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5716 - accuracy: 0.7172\n",
      "Epoch 102/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.7173\n",
      "Epoch 103/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5726 - accuracy: 0.7168\n",
      "Epoch 104/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5719 - accuracy: 0.7171\n",
      "Epoch 105/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5722 - accuracy: 0.7169\n",
      "Epoch 106/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5730 - accuracy: 0.7173\n",
      "Epoch 107/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7168\n",
      "Epoch 108/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7170\n",
      "Epoch 109/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5720 - accuracy: 0.7171\n",
      "Epoch 110/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7173\n",
      "Epoch 111/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5719 - accuracy: 0.7174\n",
      "Epoch 112/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.7173\n",
      "Epoch 113/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.7169\n",
      "Epoch 114/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7174\n",
      "Epoch 115/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5724 - accuracy: 0.7173\n",
      "Epoch 116/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7170\n",
      "Epoch 117/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7173\n",
      "Epoch 118/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7170\n",
      "Epoch 119/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7174\n",
      "Epoch 120/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7172\n",
      "Epoch 121/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7172\n",
      "Epoch 122/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7169\n",
      "Epoch 123/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7171\n",
      "Epoch 124/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7175\n",
      "Epoch 125/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7173\n",
      "Epoch 126/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7172\n",
      "Epoch 127/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7169\n",
      "Epoch 128/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5717 - accuracy: 0.7171\n",
      "Epoch 129/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7175\n",
      "Epoch 130/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7172\n",
      "Epoch 131/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5734 - accuracy: 0.7173\n",
      "Epoch 132/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5715 - accuracy: 0.7170\n",
      "Epoch 133/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5711 - accuracy: 0.7170\n",
      "Epoch 134/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.7175\n",
      "Epoch 135/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7177\n",
      "Epoch 136/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5710 - accuracy: 0.7174\n",
      "Epoch 137/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.7173\n",
      "Epoch 138/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7169\n",
      "Epoch 139/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7175\n",
      "Epoch 140/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5713 - accuracy: 0.7176\n",
      "Epoch 141/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7170\n",
      "Epoch 142/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5709 - accuracy: 0.7174\n",
      "Epoch 143/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5726 - accuracy: 0.7173\n",
      "Epoch 144/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7171\n",
      "Epoch 145/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7170\n",
      "Epoch 146/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7178\n",
      "Epoch 147/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5720 - accuracy: 0.7177\n",
      "Epoch 148/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7176\n",
      "Epoch 149/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7178\n",
      "Epoch 150/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7174\n",
      "Epoch 151/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7174\n",
      "Epoch 152/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.7172\n",
      "Epoch 153/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7175\n",
      "Epoch 154/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7171\n",
      "Epoch 155/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5709 - accuracy: 0.7176\n",
      "Epoch 156/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7178\n",
      "Epoch 157/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7174\n",
      "Epoch 158/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7176\n",
      "Epoch 159/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7178\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7180\n",
      "Epoch 161/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5709 - accuracy: 0.7174\n",
      "Epoch 162/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5715 - accuracy: 0.7177\n",
      "Epoch 163/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7171\n",
      "Epoch 164/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7177\n",
      "Epoch 165/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7176\n",
      "Epoch 166/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7175\n",
      "Epoch 167/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7173\n",
      "Epoch 168/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5715 - accuracy: 0.7173\n",
      "Epoch 169/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7172\n",
      "Epoch 170/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7170\n",
      "Epoch 171/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7173\n",
      "Epoch 172/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7174\n",
      "Epoch 173/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7173\n",
      "Epoch 174/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5708 - accuracy: 0.7173\n",
      "Epoch 175/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5709 - accuracy: 0.7170\n",
      "Epoch 176/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7178\n",
      "Epoch 177/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7174\n",
      "Epoch 178/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7176\n",
      "Epoch 179/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7175\n",
      "Epoch 180/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7173\n",
      "Epoch 181/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7175\n",
      "Epoch 182/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7181\n",
      "Epoch 183/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5709 - accuracy: 0.7175\n",
      "Epoch 184/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7175\n",
      "Epoch 185/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7175\n",
      "Epoch 186/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7179\n",
      "Epoch 187/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5718 - accuracy: 0.7175\n",
      "Epoch 188/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7179\n",
      "Epoch 189/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7178\n",
      "Epoch 190/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7176\n",
      "Epoch 191/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7177\n",
      "Epoch 192/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.7171\n",
      "Epoch 193/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5743 - accuracy: 0.7169\n",
      "Epoch 194/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7178\n",
      "Epoch 195/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7177\n",
      "Epoch 196/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5717 - accuracy: 0.7175\n",
      "Epoch 197/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7175\n",
      "Epoch 198/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7177\n",
      "Epoch 199/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7179\n",
      "Epoch 200/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7174\n",
      "215/215 - 0s - loss: 0.6056 - accuracy: 0.7117\n",
      "Loss:0.6056201457977295, Accuracy: 0.7116618156433105\n"
     ]
    }
   ],
   "source": [
    "# Compile the model \n",
    "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics= [\"accuracy\"])\n",
    "\n",
    "# Create a Callback that saves the weights every 5 epochs\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\n",
    "cp_callback= ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True, save_freq=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model= nn2.fit(X_train_scaled, y_train, epochs=200, verbose=1, callbacks=[cp_callback])\n",
    "\n",
    "# Evaluate Results\n",
    "model_loss, model_accuracy= nn2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss:{model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22b274",
   "metadata": {},
   "source": [
    "# Adding epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12a5d301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7180\n",
      "Epoch 2/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5719 - accuracy: 0.7175\n",
      "Epoch 3/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7176\n",
      "Epoch 4/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7174\n",
      "Epoch 5/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7176\n",
      "Epoch 6/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7176\n",
      "Epoch 7/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7179\n",
      "Epoch 8/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7178\n",
      "Epoch 9/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7177\n",
      "Epoch 10/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7182\n",
      "Epoch 11/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7170\n",
      "Epoch 12/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5723 - accuracy: 0.7177\n",
      "Epoch 13/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7180\n",
      "Epoch 14/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7181\n",
      "Epoch 15/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7180\n",
      "Epoch 16/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7179\n",
      "Epoch 17/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7177\n",
      "Epoch 18/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7175\n",
      "Epoch 19/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7180\n",
      "Epoch 20/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7179\n",
      "Epoch 21/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7181\n",
      "Epoch 22/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7178\n",
      "Epoch 23/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7177\n",
      "Epoch 24/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7178\n",
      "Epoch 25/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7179\n",
      "Epoch 26/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7180\n",
      "Epoch 27/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7177\n",
      "Epoch 28/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7178\n",
      "Epoch 29/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7179\n",
      "Epoch 30/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7177\n",
      "Epoch 31/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7181\n",
      "Epoch 32/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7177\n",
      "Epoch 33/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7180\n",
      "Epoch 34/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7170\n",
      "Epoch 35/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7182\n",
      "Epoch 36/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7179\n",
      "Epoch 37/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7178\n",
      "Epoch 38/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7179\n",
      "Epoch 39/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7178\n",
      "Epoch 40/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5721 - accuracy: 0.7180\n",
      "Epoch 41/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7179\n",
      "Epoch 42/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7181\n",
      "Epoch 43/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7182\n",
      "Epoch 44/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7180\n",
      "Epoch 45/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7174\n",
      "Epoch 46/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7179\n",
      "Epoch 47/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7180\n",
      "Epoch 48/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.7179\n",
      "Epoch 49/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7180\n",
      "Epoch 50/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7178\n",
      "Epoch 51/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5713 - accuracy: 0.7172\n",
      "Epoch 52/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7181\n",
      "Epoch 53/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7184\n",
      "Epoch 54/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7178\n",
      "Epoch 55/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7180\n",
      "Epoch 56/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7182\n",
      "Epoch 57/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7180\n",
      "Epoch 58/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7176\n",
      "Epoch 59/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7182\n",
      "Epoch 60/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7177\n",
      "Epoch 61/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7181\n",
      "Epoch 62/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7179\n",
      "Epoch 63/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7179\n",
      "Epoch 64/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7184\n",
      "Epoch 65/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7181\n",
      "Epoch 66/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7182\n",
      "Epoch 67/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7178\n",
      "Epoch 68/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7177\n",
      "Epoch 69/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7179\n",
      "Epoch 70/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7181\n",
      "Epoch 71/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7182\n",
      "Epoch 72/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7182\n",
      "Epoch 73/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7179\n",
      "Epoch 74/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7177\n",
      "Epoch 75/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7175\n",
      "Epoch 76/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7178\n",
      "Epoch 77/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7179\n",
      "Epoch 78/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7175\n",
      "Epoch 79/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7178\n",
      "Epoch 80/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7181\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7181\n",
      "Epoch 82/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7180\n",
      "Epoch 83/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7183\n",
      "Epoch 84/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7177\n",
      "Epoch 85/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5716 - accuracy: 0.7180\n",
      "Epoch 86/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7184\n",
      "Epoch 87/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7180\n",
      "Epoch 88/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7179\n",
      "Epoch 89/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7181\n",
      "Epoch 90/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7180\n",
      "Epoch 91/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7183\n",
      "Epoch 92/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5719 - accuracy: 0.7179\n",
      "Epoch 93/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7180\n",
      "Epoch 94/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7184\n",
      "Epoch 95/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7180\n",
      "Epoch 96/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7181\n",
      "Epoch 97/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7180\n",
      "Epoch 98/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7182\n",
      "Epoch 99/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7181\n",
      "Epoch 100/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7180\n",
      "Epoch 101/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7180\n",
      "Epoch 102/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7178\n",
      "Epoch 103/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7184\n",
      "Epoch 104/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7183\n",
      "Epoch 105/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7178\n",
      "Epoch 106/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7179\n",
      "Epoch 107/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7179\n",
      "Epoch 108/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7185\n",
      "Epoch 109/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7179\n",
      "Epoch 110/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7181\n",
      "Epoch 111/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7176\n",
      "Epoch 112/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7184\n",
      "Epoch 113/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7179\n",
      "Epoch 114/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7177\n",
      "Epoch 115/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7180\n",
      "Epoch 116/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7184\n",
      "Epoch 117/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7180\n",
      "Epoch 118/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7181\n",
      "Epoch 119/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7125\n",
      "Epoch 120/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7106\n",
      "Epoch 121/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7151\n",
      "Epoch 122/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7178\n",
      "Epoch 123/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7181\n",
      "Epoch 124/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7181\n",
      "Epoch 125/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7185\n",
      "Epoch 126/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7185\n",
      "Epoch 127/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7181\n",
      "Epoch 128/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7186\n",
      "Epoch 129/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7184\n",
      "Epoch 130/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7175\n",
      "Epoch 131/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7175\n",
      "Epoch 132/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7184\n",
      "Epoch 133/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7178\n",
      "Epoch 134/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7182\n",
      "Epoch 135/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7184\n",
      "Epoch 136/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7180\n",
      "Epoch 137/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7181\n",
      "Epoch 138/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7177\n",
      "Epoch 139/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7185\n",
      "Epoch 140/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5724 - accuracy: 0.7181\n",
      "Epoch 141/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7181\n",
      "Epoch 142/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7183\n",
      "Epoch 143/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.7186\n",
      "Epoch 144/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7182\n",
      "Epoch 145/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7181\n",
      "Epoch 146/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7186\n",
      "Epoch 147/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7182\n",
      "Epoch 148/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7181\n",
      "Epoch 149/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7178\n",
      "Epoch 150/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7183\n",
      "Epoch 151/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7181\n",
      "Epoch 152/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7184\n",
      "Epoch 153/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7181\n",
      "Epoch 154/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7183\n",
      "Epoch 155/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7181\n",
      "Epoch 156/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7181\n",
      "Epoch 157/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7182\n",
      "Epoch 158/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7184\n",
      "Epoch 159/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7184\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7181\n",
      "Epoch 161/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7181\n",
      "Epoch 162/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7180\n",
      "Epoch 163/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7182\n",
      "Epoch 164/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7181\n",
      "Epoch 165/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7182\n",
      "Epoch 166/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7180\n",
      "Epoch 167/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7181\n",
      "Epoch 168/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7183\n",
      "Epoch 169/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7185\n",
      "Epoch 170/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7184\n",
      "Epoch 171/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7184\n",
      "Epoch 172/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7185\n",
      "Epoch 173/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7183\n",
      "Epoch 174/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7182\n",
      "Epoch 175/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7185\n",
      "Epoch 176/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7186\n",
      "Epoch 177/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7179\n",
      "Epoch 178/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5729 - accuracy: 0.7181\n",
      "Epoch 179/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7181\n",
      "Epoch 180/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7186\n",
      "Epoch 181/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7183\n",
      "Epoch 182/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7178\n",
      "Epoch 183/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7182\n",
      "Epoch 184/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7184\n",
      "Epoch 185/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7179\n",
      "Epoch 186/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7184\n",
      "Epoch 187/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7185\n",
      "Epoch 188/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7187\n",
      "Epoch 189/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7182\n",
      "Epoch 190/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7185\n",
      "Epoch 191/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7184\n",
      "Epoch 192/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5717 - accuracy: 0.7178\n",
      "Epoch 193/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7183\n",
      "Epoch 194/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7182\n",
      "Epoch 195/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7182\n",
      "Epoch 196/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7184\n",
      "Epoch 197/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.7185\n",
      "Epoch 198/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7184\n",
      "Epoch 199/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7181\n",
      "Epoch 200/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7186\n",
      "Epoch 201/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7184\n",
      "Epoch 202/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7179\n",
      "Epoch 203/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7182\n",
      "Epoch 204/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7182\n",
      "Epoch 205/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7184\n",
      "Epoch 206/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7183\n",
      "Epoch 207/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7181\n",
      "Epoch 208/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7185\n",
      "Epoch 209/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7178\n",
      "Epoch 210/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7183\n",
      "Epoch 211/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7179\n",
      "Epoch 212/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7184\n",
      "Epoch 213/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7187\n",
      "Epoch 214/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7185\n",
      "Epoch 215/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7181\n",
      "Epoch 216/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7185\n",
      "Epoch 217/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7186\n",
      "Epoch 218/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7183\n",
      "Epoch 219/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7183\n",
      "Epoch 220/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7186\n",
      "Epoch 221/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7186\n",
      "Epoch 222/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7180\n",
      "Epoch 223/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7185\n",
      "Epoch 224/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7186\n",
      "Epoch 225/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7187\n",
      "Epoch 226/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7181\n",
      "Epoch 227/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7184\n",
      "Epoch 228/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7180\n",
      "Epoch 229/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7185\n",
      "Epoch 230/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7183\n",
      "Epoch 231/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7180\n",
      "Epoch 232/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7185\n",
      "Epoch 233/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7182\n",
      "Epoch 234/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7189\n",
      "Epoch 235/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7184\n",
      "Epoch 236/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7185\n",
      "Epoch 237/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7185\n",
      "Epoch 238/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7183\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7188\n",
      "Epoch 240/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7187\n",
      "Epoch 241/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7182\n",
      "Epoch 242/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7176\n",
      "Epoch 243/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7178\n",
      "Epoch 244/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7184\n",
      "Epoch 245/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7182\n",
      "Epoch 246/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7184\n",
      "Epoch 247/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7189\n",
      "Epoch 248/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7185\n",
      "Epoch 249/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7185\n",
      "Epoch 250/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.7184\n",
      "Epoch 251/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7190\n",
      "Epoch 252/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7186\n",
      "Epoch 253/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.7183\n",
      "Epoch 254/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7185\n",
      "Epoch 255/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7184\n",
      "Epoch 256/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7186\n",
      "Epoch 257/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7186\n",
      "Epoch 258/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7180\n",
      "Epoch 259/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.7186\n",
      "Epoch 260/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7179\n",
      "Epoch 261/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7184\n",
      "Epoch 262/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7183\n",
      "Epoch 263/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7185\n",
      "Epoch 264/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7185\n",
      "Epoch 265/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7187\n",
      "Epoch 266/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7188\n",
      "Epoch 267/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7188\n",
      "Epoch 268/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7186\n",
      "Epoch 269/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7186\n",
      "Epoch 270/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7185\n",
      "Epoch 271/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.7185\n",
      "Epoch 272/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7187\n",
      "Epoch 273/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7187\n",
      "Epoch 274/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7181\n",
      "Epoch 275/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5738 - accuracy: 0.7181\n",
      "Epoch 276/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7185\n",
      "Epoch 277/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7185\n",
      "Epoch 278/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7185\n",
      "Epoch 279/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7186\n",
      "Epoch 280/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7186\n",
      "Epoch 281/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7182\n",
      "Epoch 282/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.7186\n",
      "Epoch 283/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5870 - accuracy: 0.7180\n",
      "Epoch 284/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5793 - accuracy: 0.7181\n",
      "Epoch 285/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7184\n",
      "Epoch 286/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7184\n",
      "Epoch 287/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7185\n",
      "Epoch 288/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7184\n",
      "Epoch 289/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7186\n",
      "Epoch 290/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7185\n",
      "Epoch 291/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7188\n",
      "Epoch 292/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7182\n",
      "Epoch 293/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7185\n",
      "Epoch 294/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7182\n",
      "Epoch 295/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7185\n",
      "Epoch 296/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7180\n",
      "Epoch 297/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7185\n",
      "Epoch 298/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7184\n",
      "Epoch 299/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7187\n",
      "Epoch 300/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7185\n",
      "Epoch 301/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7187\n",
      "Epoch 302/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7183\n",
      "Epoch 303/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7185\n",
      "Epoch 304/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7180\n",
      "Epoch 305/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7181\n",
      "Epoch 306/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7184\n",
      "Epoch 307/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7184\n",
      "Epoch 308/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7185\n",
      "Epoch 309/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7184\n",
      "Epoch 310/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5938 - accuracy: 0.7182\n",
      "Epoch 311/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7184\n",
      "Epoch 312/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7186\n",
      "Epoch 313/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.7186\n",
      "Epoch 314/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7184\n",
      "Epoch 315/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7186\n",
      "Epoch 316/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7184\n",
      "Epoch 317/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7184\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7186\n",
      "Epoch 319/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7185\n",
      "Epoch 320/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7186\n",
      "Epoch 321/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7188\n",
      "Epoch 322/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7182\n",
      "Epoch 323/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7183\n",
      "Epoch 324/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7188\n",
      "Epoch 325/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7186\n",
      "Epoch 326/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7182\n",
      "Epoch 327/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7188\n",
      "Epoch 328/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7186\n",
      "Epoch 329/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7187\n",
      "Epoch 330/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5682 - accuracy: 0.7186\n",
      "Epoch 331/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7184\n",
      "Epoch 332/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7183\n",
      "Epoch 333/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7187\n",
      "Epoch 334/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5697 - accuracy: 0.7184\n",
      "Epoch 335/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7187\n",
      "Epoch 336/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7188\n",
      "Epoch 337/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7187\n",
      "Epoch 338/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7186\n",
      "Epoch 339/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5693 - accuracy: 0.7187\n",
      "Epoch 340/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7187\n",
      "Epoch 341/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5687 - accuracy: 0.7185\n",
      "Epoch 342/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7185\n",
      "Epoch 343/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7186\n",
      "Epoch 344/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7185\n",
      "Epoch 345/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7189\n",
      "Epoch 346/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7187\n",
      "Epoch 347/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5693 - accuracy: 0.7181\n",
      "Epoch 348/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7186\n",
      "Epoch 349/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7186\n",
      "Epoch 350/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5687 - accuracy: 0.7189\n",
      "Epoch 351/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5695 - accuracy: 0.7185\n",
      "Epoch 352/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7187\n",
      "Epoch 353/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7189\n",
      "Epoch 354/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7184\n",
      "Epoch 355/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7189\n",
      "Epoch 356/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7187\n",
      "Epoch 357/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7187\n",
      "Epoch 358/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7185\n",
      "Epoch 359/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5680 - accuracy: 0.7190\n",
      "Epoch 360/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5680 - accuracy: 0.7188\n",
      "Epoch 361/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7189\n",
      "Epoch 362/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.7188\n",
      "Epoch 363/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7186\n",
      "Epoch 364/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7189\n",
      "Epoch 365/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.7187\n",
      "Epoch 366/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7186\n",
      "Epoch 367/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.7189\n",
      "Epoch 368/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7187\n",
      "Epoch 369/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7186\n",
      "Epoch 370/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5680 - accuracy: 0.7185\n",
      "Epoch 371/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7179\n",
      "Epoch 372/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7186\n",
      "Epoch 373/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7186\n",
      "Epoch 374/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7189\n",
      "Epoch 375/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7186\n",
      "Epoch 376/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7186\n",
      "Epoch 377/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7189\n",
      "Epoch 378/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7188\n",
      "Epoch 379/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7188\n",
      "Epoch 380/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.7190\n",
      "Epoch 381/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7185\n",
      "Epoch 382/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7191\n",
      "Epoch 383/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7186\n",
      "Epoch 384/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7190\n",
      "Epoch 385/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7188\n",
      "Epoch 386/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7189\n",
      "Epoch 387/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5676 - accuracy: 0.7189\n",
      "Epoch 388/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7184\n",
      "Epoch 389/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7182\n",
      "Epoch 390/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7188\n",
      "Epoch 391/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.7183\n",
      "Epoch 392/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5680 - accuracy: 0.7187\n",
      "Epoch 393/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7187\n",
      "Epoch 394/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.7185\n",
      "Epoch 395/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.7185\n",
      "Epoch 396/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7185\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5677 - accuracy: 0.7186\n",
      "Epoch 398/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7188\n",
      "Epoch 399/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7189\n",
      "Epoch 400/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7190\n",
      "Epoch 401/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7191\n",
      "Epoch 402/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5680 - accuracy: 0.7185\n",
      "Epoch 403/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7186\n",
      "Epoch 404/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7185\n",
      "Epoch 405/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7189\n",
      "Epoch 406/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7187\n",
      "Epoch 407/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7184\n",
      "Epoch 408/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7181\n",
      "Epoch 409/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5677 - accuracy: 0.7188\n",
      "Epoch 410/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7185\n",
      "Epoch 411/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7190\n",
      "Epoch 412/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.7184\n",
      "Epoch 413/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7186\n",
      "Epoch 414/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7181\n",
      "Epoch 415/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7181\n",
      "Epoch 416/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7188\n",
      "Epoch 417/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7189\n",
      "Epoch 418/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5675 - accuracy: 0.7190\n",
      "Epoch 419/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7191\n",
      "Epoch 420/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.7185\n",
      "Epoch 421/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7186\n",
      "Epoch 422/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7186\n",
      "Epoch 423/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.7184\n",
      "Epoch 424/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5695 - accuracy: 0.7184\n",
      "Epoch 425/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7185\n",
      "Epoch 426/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7176\n",
      "Epoch 427/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7189\n",
      "Epoch 428/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7182\n",
      "Epoch 429/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5880 - accuracy: 0.7176\n",
      "Epoch 430/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.7184\n",
      "Epoch 431/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5677 - accuracy: 0.7185\n",
      "Epoch 432/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5674 - accuracy: 0.7185\n",
      "Epoch 433/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7188\n",
      "Epoch 434/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7184\n",
      "Epoch 435/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7182\n",
      "Epoch 436/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7186\n",
      "Epoch 437/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7185\n",
      "Epoch 438/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7189\n",
      "Epoch 439/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5680 - accuracy: 0.7186\n",
      "Epoch 440/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5677 - accuracy: 0.7186\n",
      "Epoch 441/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7182\n",
      "Epoch 442/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5816 - accuracy: 0.7184\n",
      "Epoch 443/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7183\n",
      "Epoch 444/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7187\n",
      "Epoch 445/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7187\n",
      "Epoch 446/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7186\n",
      "Epoch 447/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7184\n",
      "Epoch 448/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7186\n",
      "Epoch 449/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7188\n",
      "Epoch 450/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7189\n",
      "Epoch 451/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7184\n",
      "Epoch 452/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7188\n",
      "Epoch 453/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7184\n",
      "Epoch 454/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7182\n",
      "Epoch 455/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7185\n",
      "Epoch 456/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7192\n",
      "Epoch 457/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5676 - accuracy: 0.7187\n",
      "Epoch 458/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7188\n",
      "Epoch 459/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7184\n",
      "Epoch 460/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7186\n",
      "Epoch 461/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7185\n",
      "Epoch 462/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7185\n",
      "Epoch 463/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7187\n",
      "Epoch 464/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.7186\n",
      "Epoch 465/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5680 - accuracy: 0.7187\n",
      "Epoch 466/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5682 - accuracy: 0.7190\n",
      "Epoch 467/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.7183\n",
      "Epoch 468/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.7186\n",
      "Epoch 469/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7186\n",
      "Epoch 470/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7192\n",
      "Epoch 471/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5675 - accuracy: 0.7190\n",
      "Epoch 472/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5674 - accuracy: 0.7189\n",
      "Epoch 473/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7188\n",
      "Epoch 474/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7184\n",
      "Epoch 475/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5677 - accuracy: 0.7186\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7186\n",
      "Epoch 477/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5685 - accuracy: 0.7184\n",
      "Epoch 478/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7189\n",
      "Epoch 479/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5675 - accuracy: 0.7187\n",
      "Epoch 480/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5680 - accuracy: 0.7187\n",
      "Epoch 481/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7185\n",
      "Epoch 482/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7186\n",
      "Epoch 483/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5692 - accuracy: 0.7187\n",
      "Epoch 484/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7190\n",
      "Epoch 485/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7190\n",
      "Epoch 486/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5678 - accuracy: 0.7190\n",
      "Epoch 487/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5678 - accuracy: 0.7189\n",
      "Epoch 488/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7184\n",
      "Epoch 489/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5697 - accuracy: 0.7184\n",
      "Epoch 490/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5682 - accuracy: 0.7189\n",
      "Epoch 491/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7192\n",
      "Epoch 492/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5678 - accuracy: 0.7189\n",
      "Epoch 493/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7190\n",
      "Epoch 494/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7187\n",
      "Epoch 495/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7194\n",
      "Epoch 496/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7185\n",
      "Epoch 497/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5682 - accuracy: 0.7189\n",
      "Epoch 498/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7187\n",
      "Epoch 499/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7191\n",
      "Epoch 500/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5672 - accuracy: 0.7191\n",
      "215/215 - 0s - loss: 0.7422 - accuracy: 0.7120\n",
      "Loss:0.7422379851341248, Accuracy: 0.711953341960907\n"
     ]
    }
   ],
   "source": [
    "# Compile the model \n",
    "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics= [\"accuracy\"])\n",
    "\n",
    "# Create a Callback that saves the weights every 5 epochs\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\n",
    "cp_callback= ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True, save_freq=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model= nn2.fit(X_train_scaled, y_train, epochs=500, verbose=1, callbacks=[cp_callback])\n",
    "\n",
    "# Evaluate Results\n",
    "model_loss, model_accuracy= nn2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss:{model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c80c9e9",
   "metadata": {},
   "source": [
    "# Change activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "84a770d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 100)               3200      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 15,851\n",
      "Trainable params: 15,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "num_input = len(X_train[0])\n",
    "hidden_nodes1 = 100\n",
    "hidden_nodes2 = 50\n",
    "hidden_nodes3= 25\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes1, input_dim = num_input,\n",
    "                                    activation =\"sigmoid\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units = hidden_nodes1, activation=\"sigmoid\"))\n",
    "\n",
    "# Third Hidden Layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes3, activation=\"sigmoid\"))\n",
    "\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units = 1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "447dee38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.6240 - accuracy: 0.6734\n",
      "Epoch 2/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.6912\n",
      "Epoch 3/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6934\n",
      "Epoch 4/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.6960\n",
      "Epoch 5/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6961\n",
      "Epoch 6/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5920 - accuracy: 0.6981\n",
      "Epoch 7/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5903 - accuracy: 0.7007\n",
      "Epoch 8/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5891 - accuracy: 0.7014\n",
      "Epoch 9/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5876 - accuracy: 0.7035\n",
      "Epoch 10/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5861 - accuracy: 0.7060\n",
      "Epoch 11/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5854 - accuracy: 0.7068\n",
      "Epoch 12/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5845 - accuracy: 0.7074\n",
      "Epoch 13/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5840 - accuracy: 0.7084\n",
      "Epoch 14/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5828 - accuracy: 0.7108\n",
      "Epoch 15/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5824 - accuracy: 0.7099\n",
      "Epoch 16/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5817 - accuracy: 0.7107\n",
      "Epoch 17/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5812 - accuracy: 0.7107\n",
      "Epoch 18/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5807 - accuracy: 0.7110\n",
      "Epoch 19/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.7111\n",
      "Epoch 20/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5807 - accuracy: 0.7105\n",
      "Epoch 21/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5802 - accuracy: 0.7118\n",
      "Epoch 22/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5796 - accuracy: 0.7101\n",
      "Epoch 23/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5800 - accuracy: 0.7116\n",
      "Epoch 24/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5796 - accuracy: 0.7128\n",
      "Epoch 25/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5794 - accuracy: 0.7122\n",
      "Epoch 26/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5788 - accuracy: 0.7128\n",
      "Epoch 27/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5786 - accuracy: 0.7128\n",
      "Epoch 28/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5783 - accuracy: 0.7127\n",
      "Epoch 29/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5782 - accuracy: 0.7126\n",
      "Epoch 30/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5781 - accuracy: 0.7137\n",
      "Epoch 31/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5778 - accuracy: 0.7138\n",
      "Epoch 32/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5778 - accuracy: 0.7131\n",
      "Epoch 33/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5772 - accuracy: 0.7138\n",
      "Epoch 34/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5773 - accuracy: 0.7129\n",
      "Epoch 35/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5772 - accuracy: 0.7142\n",
      "Epoch 36/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5770 - accuracy: 0.7147\n",
      "Epoch 37/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5769 - accuracy: 0.7137\n",
      "Epoch 38/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5770 - accuracy: 0.7142\n",
      "Epoch 39/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5768 - accuracy: 0.7142\n",
      "Epoch 40/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5764 - accuracy: 0.7153\n",
      "Epoch 41/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5764 - accuracy: 0.7142\n",
      "Epoch 42/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5763 - accuracy: 0.7153\n",
      "Epoch 43/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5759 - accuracy: 0.7145\n",
      "Epoch 44/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5763 - accuracy: 0.7149\n",
      "Epoch 45/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5760 - accuracy: 0.7141\n",
      "Epoch 46/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5760 - accuracy: 0.7139\n",
      "Epoch 47/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5758 - accuracy: 0.7154\n",
      "Epoch 48/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5755 - accuracy: 0.7148\n",
      "Epoch 49/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5756 - accuracy: 0.7159\n",
      "Epoch 50/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5755 - accuracy: 0.7144\n",
      "Epoch 51/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5753 - accuracy: 0.7155\n",
      "Epoch 52/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5751 - accuracy: 0.7145\n",
      "Epoch 53/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5748 - accuracy: 0.7159\n",
      "Epoch 54/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5750 - accuracy: 0.7152\n",
      "Epoch 55/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5748 - accuracy: 0.7156\n",
      "Epoch 56/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5747 - accuracy: 0.7151\n",
      "Epoch 57/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5748 - accuracy: 0.7153\n",
      "Epoch 58/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5745 - accuracy: 0.7159\n",
      "Epoch 59/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5746 - accuracy: 0.7155\n",
      "Epoch 60/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5745 - accuracy: 0.7161\n",
      "Epoch 61/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5742 - accuracy: 0.7152\n",
      "Epoch 62/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5743 - accuracy: 0.7159\n",
      "Epoch 63/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5741 - accuracy: 0.7157\n",
      "Epoch 64/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5742 - accuracy: 0.7160\n",
      "Epoch 65/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5737 - accuracy: 0.7164\n",
      "Epoch 66/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5741 - accuracy: 0.7163\n",
      "Epoch 67/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5739 - accuracy: 0.7157\n",
      "Epoch 68/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5739 - accuracy: 0.7154\n",
      "Epoch 69/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5737 - accuracy: 0.7163\n",
      "Epoch 70/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5734 - accuracy: 0.7165\n",
      "Epoch 71/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5737 - accuracy: 0.7166\n",
      "Epoch 72/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5736 - accuracy: 0.7162\n",
      "Epoch 73/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5734 - accuracy: 0.7161\n",
      "Epoch 74/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5729 - accuracy: 0.7160\n",
      "Epoch 75/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5731 - accuracy: 0.7167\n",
      "Epoch 76/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5730 - accuracy: 0.7166\n",
      "Epoch 77/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5731 - accuracy: 0.7169\n",
      "Epoch 78/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5730 - accuracy: 0.7166\n",
      "Epoch 79/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5729 - accuracy: 0.7168\n",
      "Epoch 80/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5731 - accuracy: 0.7154\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.7158\n",
      "Epoch 82/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.7155\n",
      "Epoch 83/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5725 - accuracy: 0.7169\n",
      "Epoch 84/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5729 - accuracy: 0.7166\n",
      "Epoch 85/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.7161\n",
      "Epoch 86/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5726 - accuracy: 0.7165\n",
      "Epoch 87/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5724 - accuracy: 0.7161\n",
      "Epoch 88/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5726 - accuracy: 0.7166\n",
      "Epoch 89/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5722 - accuracy: 0.7168\n",
      "Epoch 90/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5724 - accuracy: 0.7170\n",
      "Epoch 91/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5723 - accuracy: 0.7168\n",
      "Epoch 92/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5722 - accuracy: 0.7170\n",
      "Epoch 93/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5722 - accuracy: 0.7173\n",
      "Epoch 94/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5721 - accuracy: 0.7162\n",
      "Epoch 95/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5721 - accuracy: 0.7173\n",
      "Epoch 96/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5720 - accuracy: 0.7165\n",
      "Epoch 97/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5722 - accuracy: 0.7166\n",
      "Epoch 98/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.7166\n",
      "Epoch 99/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5718 - accuracy: 0.7161\n",
      "Epoch 100/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5720 - accuracy: 0.7166\n",
      "Epoch 101/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5717 - accuracy: 0.7164\n",
      "Epoch 102/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5718 - accuracy: 0.7166\n",
      "Epoch 103/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5717 - accuracy: 0.7164\n",
      "Epoch 104/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5717 - accuracy: 0.7165\n",
      "Epoch 105/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5717 - accuracy: 0.7172\n",
      "Epoch 106/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7173\n",
      "Epoch 107/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.7169\n",
      "Epoch 108/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5716 - accuracy: 0.7171\n",
      "Epoch 109/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5716 - accuracy: 0.7173\n",
      "Epoch 110/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5715 - accuracy: 0.7165\n",
      "Epoch 111/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7168\n",
      "Epoch 112/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5713 - accuracy: 0.7175\n",
      "Epoch 113/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5713 - accuracy: 0.7171\n",
      "Epoch 114/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5713 - accuracy: 0.7168\n",
      "Epoch 115/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7167\n",
      "Epoch 116/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7172\n",
      "Epoch 117/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7175\n",
      "Epoch 118/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7170\n",
      "Epoch 119/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7173\n",
      "Epoch 120/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7166\n",
      "Epoch 121/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7175\n",
      "Epoch 122/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.7175\n",
      "Epoch 123/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5711 - accuracy: 0.7177\n",
      "Epoch 124/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7174\n",
      "Epoch 125/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7174\n",
      "Epoch 126/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7172\n",
      "Epoch 127/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7173\n",
      "Epoch 128/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5710 - accuracy: 0.7175\n",
      "Epoch 129/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5709 - accuracy: 0.7171\n",
      "Epoch 130/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7174\n",
      "Epoch 131/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7179\n",
      "Epoch 132/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5709 - accuracy: 0.7172\n",
      "Epoch 133/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5708 - accuracy: 0.7177\n",
      "Epoch 134/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7177\n",
      "Epoch 135/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5708 - accuracy: 0.7175\n",
      "Epoch 136/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7179\n",
      "Epoch 137/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7173\n",
      "Epoch 138/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5703 - accuracy: 0.7179\n",
      "Epoch 139/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7170\n",
      "Epoch 140/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7174\n",
      "Epoch 141/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7172\n",
      "Epoch 142/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7172\n",
      "Epoch 143/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5704 - accuracy: 0.7176\n",
      "Epoch 144/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7176\n",
      "Epoch 145/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7177\n",
      "Epoch 146/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7168\n",
      "Epoch 147/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5707 - accuracy: 0.7177\n",
      "Epoch 148/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7180\n",
      "Epoch 149/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5704 - accuracy: 0.7175\n",
      "Epoch 150/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7174\n",
      "Epoch 151/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7167\n",
      "Epoch 152/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7176\n",
      "Epoch 153/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7170\n",
      "Epoch 154/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7174\n",
      "Epoch 155/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5705 - accuracy: 0.7172\n",
      "Epoch 156/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7172\n",
      "Epoch 157/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5703 - accuracy: 0.7172\n",
      "Epoch 158/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5700 - accuracy: 0.7173\n",
      "Epoch 159/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7172\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.7176\n",
      "Epoch 161/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7176\n",
      "Epoch 162/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7172\n",
      "Epoch 163/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5702 - accuracy: 0.7174\n",
      "Epoch 164/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.7174\n",
      "Epoch 165/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7176\n",
      "Epoch 166/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7180\n",
      "Epoch 167/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7175\n",
      "Epoch 168/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5703 - accuracy: 0.7173\n",
      "Epoch 169/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7177\n",
      "Epoch 170/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7179\n",
      "Epoch 171/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7172\n",
      "Epoch 172/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7173\n",
      "Epoch 173/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7178\n",
      "Epoch 174/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7172\n",
      "Epoch 175/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7178\n",
      "Epoch 176/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7174\n",
      "Epoch 177/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7179\n",
      "Epoch 178/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7178\n",
      "Epoch 179/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7176\n",
      "Epoch 180/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7176\n",
      "Epoch 181/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.7174\n",
      "Epoch 182/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7175\n",
      "Epoch 183/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7173\n",
      "Epoch 184/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7173\n",
      "Epoch 185/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7184\n",
      "Epoch 186/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7176\n",
      "Epoch 187/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7182\n",
      "Epoch 188/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5698 - accuracy: 0.7177\n",
      "Epoch 189/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5697 - accuracy: 0.7177\n",
      "Epoch 190/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5697 - accuracy: 0.7177\n",
      "Epoch 191/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7178\n",
      "Epoch 192/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7188\n",
      "Epoch 193/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7180\n",
      "Epoch 194/200\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5697 - accuracy: 0.7177\n",
      "Epoch 195/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7178\n",
      "Epoch 196/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7181\n",
      "Epoch 197/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7181\n",
      "Epoch 198/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5698 - accuracy: 0.7178\n",
      "Epoch 199/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7182\n",
      "Epoch 200/200\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7179\n",
      "215/215 - 0s - loss: 0.5961 - accuracy: 0.7118\n",
      "Loss:0.5961416959762573, Accuracy: 0.7118076086044312\n"
     ]
    }
   ],
   "source": [
    "# Compile the model \n",
    "nn3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics= [\"accuracy\"])\n",
    "\n",
    "# Create a Callback that saves the weights every 5 epochs\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\n",
    "cp_callback= ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True, save_freq=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model= nn3.fit(X_train_scaled, y_train, epochs=200, verbose=1, callbacks=[cp_callback])\n",
    "\n",
    "# Evaluate Results\n",
    "model_loss, model_accuracy= nn3.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss:{model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60edc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn2.save(\"AlphabetSoupCharity_optimzation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd2799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
